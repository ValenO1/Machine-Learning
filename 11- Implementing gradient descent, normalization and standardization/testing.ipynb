{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GradientDescentRegressor:\n",
    "    def __init__(self, learning_rate = .01, epochs = 1000, type = \"batch\", batch_size = 20, penalty = None, alpha = .1, l1_ratio = .5, random_state= None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.type = type\n",
    "        self.batch_size = batch_size\n",
    "        self.penalty = penalty\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.weights = None\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features + 1)\n",
    "        bias = np.ones(n_samples)\n",
    "        X = np.c_[bias, X]\n",
    "        for epoch in range(self.epochs):\n",
    "            if self.type == \"batch\":\n",
    "                gradient = self._compute_gradient(X, y)\n",
    "            elif self.type == \"mini batch\":\n",
    "                indices = np.random.choice(n_samples, self.batch_size, replace=False)\n",
    "                gradient = self._compute_gradient(X[indices], y[indices])\n",
    "            elif self.type == \"stochastic\":\n",
    "                index = np.random.choice(n_samples)\n",
    "                gradient = self._compute_gradient(X[[index]], y[[index]])\n",
    "            else:\n",
    "                raise TypeError(\"only batch, mini batch and stochastic are supported\")\n",
    "\n",
    "            self.weights -= self.learning_rate * 1 / (2*n_samples) * gradient\n",
    "        self.y_mean = np.mean(y)\n",
    "            \n",
    "            \n",
    "    def _compute_gradient(self, X, y):\n",
    "        gradient = -2 * X.T.dot(y) + 2 * X.T.dot(X).dot(self.weights)\n",
    "        if self.penalty is not None:\n",
    "            if self.penalty ==\"l1\":\n",
    "                penalty = self.alpha * np.sign(self.weights)\n",
    "            elif self.penalty == \"l2\":\n",
    "                penalty = 2 * self.alpha * self.weights\n",
    "            elif self.penalty == \"elastic net\":\n",
    "                l1_penalty = self.l1_ratio * self.alpha * np.sign(self.weights)\n",
    "                l2_penalty = (1 - self.l1_ratio) * self.alpha * self.weights\n",
    "                penalty = self.alpha * (l1_penalty + l2_penalty)\n",
    "            else:\n",
    "                raise ValueError(\"penalty can be None, l1, l2 or elastic net\")\n",
    "            \n",
    "            gradient[1:] += penalty[1:]\n",
    "        return gradient\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        bias = np.ones(X.shape[0])\n",
    "        X = np.c_[bias, X]\n",
    "        return X.dot(self.weights)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        sst = np.sum((y - self.y_mean)**2)\n",
    "        sse = np.sum((y - y_pred)**2) \n",
    "        r_square = 1 - (sse / sst)\n",
    "        return r_square       \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X, y = make_regression(n_samples=1000, n_features=4, noise=50, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "poly = PolynomialFeatures(degree=5)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.901975828548115\n",
      "0.7847836703653526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-981227260.2702419\n",
      "-161337893.0906584\n"
     ]
    }
   ],
   "source": [
    "model = GradientDescentRegressor(learning_rate=.01,epochs=10000,type = 'stochastic', batch_size= 20,penalty=None, random_state=0)\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-77262.00945481856\n",
      "-34554.609258156495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "model = SGDRegressor(eta0=.0001,max_iter=50000)\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
